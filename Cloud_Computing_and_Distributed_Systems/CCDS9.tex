\section{Synchronization and coordination in distributed systems}
This section introduces a collection of algorithms whose goals vary but that shares an aim that is fundamental in distributed systems: for a set of processes to synchronize and to coordinate their actions or to agree on one or more values.\\
When we talk about synchronization is important to distinguish:
\begin{itemize}
	\item \textbf{Internal:} agreement of a set of processes. In this case, for example we can consider an \textit{election} algorithm.
	\item \textbf{External:} forced by an external agent.
\end{itemize}
In distributed systems there are several problems to analyze as:
\begin{itemize}
	\item Clock synchronization.
	\item Mutual exclusion.
	\item Election algorithm.
	\item Atomic transactions.
	\item Deadlock management.
\end{itemize}

\subsection{Mutual exclusion}
\textit{Mutual exclusion} in distributed systems can be considered as the coordination activity among a set of processes to share resources and keep consistency in the distributed system.\\
Distributed mutual exclusion of a set of resources is characterized by three main features:
\begin{itemize}
	\item \textbf{Safety:} at most one process at time executes the critical section.
	\item \textbf{Liveness:} A process that asks to enter in a critical section eventually enters it and at the end it leaves it (no \textit{deadlock} and no \textit{starvation}).
	\item \textbf{Ordering:} entering a critical section occurs accordingly to the causal ordering.
\end{itemize}

\subsection{Central server algorithm}
It has a simple implementation, in fact, it simulates the primitives offered by the centralized system through a coordinator process. Its standard behavior is structured as follow:
\begin{itemize}
	\item A process asks the coordinator to enter and it is possibly blocked.
	\item The answer is an access \textbf{token}.
	\item At receiving time of the answer, it enters the critical section.
	\item At the exit time from the critical section it communicates to the coordinator (it returns the \textit{token}).
\end{itemize}
\image{img/centralServerAlgorithm}{Server Managing a mutual exclusion token for a set of processes: centralized algorithm.}{0.6}

\subsection{Distributed algorithm}
Distributed algorithm works under the assumption that there exists a global ordering of events (\textit{reliable transmission}).
According to the different phases of the algorithm are present different protocols as:
\begin{itemize}
	\item Protocol to enter/exit critical section:
		\begin{itemize}
			\item A process that wants to enter a critical section sends a message to all the other processes, via \textit{multicast} with the name of the critical section, its own identifier and the local \textit{timestamp}.
			\item It waits for the answer from all the processes.
			\item Once all the \verb|OK| have been received, it enters the critical section.
			\item At the exit time from the critical section, it sends \verb|OK| to all the processes in the local queue. 
		\end{itemize}
	\item Protocol to receive a request:
		\begin{itemize}
			\item Be out of the required critical section and it doesn't want to enter $\rightarrow$ sends \verb|OK| to the sender.
			\item Be in the critical section $\rightarrow$ it doesn't answer and put the message in a local queue.
			\item Wants to enter the critical section $\rightarrow$ compares the \textit{timestamp} and the oldest has higher priority, if it is the other process, it sends the \verb|OK|, otherwise, if it is itself, it put the message in the local queue.
		\end{itemize}
\end{itemize}
The exposed algorithm take the name of \textbf{Ricart and Agrawala's} algorithm.
\image{img/multicastSynchronization}{Multicast synchronization}{0.6}
A distributed algorithm satisfies the criteria of mutual exclusion (\textit{safety}, \textit{liveness} and \textit{ordering}). Moreover, it is totally distributed, without a central element of control.
Some disadvantages instead are the high traffic generated by $N$ processes that require $2(N-1)$ messages for the multicast request and the answers,
the fault of the system if one of the processes crashed (other processes will
wait its answer) and the possible bottleneck introduced by processes.

\subsection{Ring algorithm}
Processes share a \textit{token} using a \textbf{local ring} structure, there are so a circular ordering of the processes. The first process has a \textit{token} that uses and then it forwards to the next one. The process that has the \textit{token} is enabled to access the critical section.\\
This particular algorithm verifies condition 1 and 2 but not condition 3.
It has the following features:
\begin{itemize}
	\item \textbf{Costs:} $[1,N-1]$ messages to obtain the token, $1$ message to exit the critical section and $[1,N-1]$ messages to synchronize on the critical section.
	\item \textbf{Reliability:} in some situations it is necessary to rebuild the logical ring (process faults) or to make an election of the next process that will have the token (process have a token faults).
	\item \textbf{Performance:} the algorithm always requires bandwidth to transmit the token even if none ask for the critical section.
\end{itemize}
\image{img/ringAlgorithm}{A ring of processes transferring a mutual exclusion token.}{0.45}

\subsection{Voting algorithm}
In order to enter a critical section, it is necessary to synchronize only a subset of the interested processes, election algorithms are in fact used in the subset. The processes make a vote to decide which process can enter the critical section:
\begin{itemize}
	\item Vote set $V_i$ is subset of $\{p_1, \dots, p_N \}$, associated to each process $p_i$.
	\item A process that wants to enter a critical section sends a message to all the other processes in $V_i$.
	\item It waits for all the \textit{reply}.
	\item Once all the \verb|OK| have been received, it enters the critical section.
	\item At the exit time from the critical section, it sends \textit{release} to all the other members of $V_i$.
	\item A process $p_j$ in $V_i$ that receives the request $\rightarrow$ if its state is \verb|HELD| or it already answered after having received the last message \textit{release} doesn't answer and put the request in a local queue, otherwise it immediately answer with a \textit{reply}.
	\item A process that receives a \textit{release} takes a requests from the queue and sends a \textit{reply}.
\end{itemize}
This algorithm takes the name as \textbf{Maekawa's} algorithm.

\subsection{Comparison}
\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hline
		\multicolumn{1}{|c|}{\textbf{Algorithms}} &
		\multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Cost of critical \\ section\\
					(enter/exit)\end{tabular}}} &
		\multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Delay\\ (enter/exit)\end{tabular}}}
		& \multicolumn{1}{c|}{\textbf{Problems}}                                       \\ \hline
		\textit{Centralised} & 3 & 2 & Coordinator fault \\ \hline
		\textit{Distributed} & $2(n-1)$ & $2(n-1)$ & Process crash\\ \hline
		\textit{Ring} & $[1,n]$ & $[0,n-1]$ & \begin{tabular}[c]{@{}l@{}}Token loss\\ 
			Process crash\end{tabular} \\ \hline
		\textit{Vote} & 
		\begin{tabular}[c]{@{}l@{}}$2\sqrt{n}$\\$\sqrt{n}$\end{tabular}
		& \begin{tabular}[c]{@{}l@{}}$2\sqrt{n}$\\$\sqrt{n}$\end{tabular}
		& \begin{tabular}[c]{@{}l@{}}Process crash of \\ the voting group\end{tabular} \\ \hline
	\end{tabular}
\end{center}

\subsection{Election algorithms}
The goal of this kind of algorithms is the fact that at the end of the algorithm all the processes agree on an \textbf{elected process} that act as \textbf{coordinator} in the distributed system.\\
The following assumptions are needed:
\begin{itemize}
	\item All the processes are uniquely numbered.
	\item The coordinator has usually the highest number among the "live" processes.
	\item Each process knows the number of all the other processes.
\end{itemize}
Generally, a process calls an election and at the end of the algorithm, all the processes agrees on the same \textbf{elected process}.

\paragraph*{Circular ordering.} One possible election algorithm can be the \textit{circular ordering}. It is structured as a logical ring composed by an ordered list of live processes in which the election message is sent only to the next process. The algorithm needs two further assumptions: the communication is reliable and processes can have faults. It works as follows:
\begin{itemize}
	\item Every process at the beginning is \textbf{non participant}, it will become \textbf{participant} adding its name to the list.
	\item If the election message id is \textbf{greater}, it passes and becomes participant.
	\item If the election message id is \textbf{smaller}, it put its own id and passes (if it is not already participant).
	\item If the election message id is \textbf{the same}, then is a \textbf{coordinator} and becomes a \textit{non participant}, sends an \textbf{elected} message.
	\item Every other process that receives an \textbf{elected} message is marked as \textit{non participant}.
\end{itemize}
\image{img/circularOrderingRing}{A ring-based election in progress.}{0.6}
In the worst case, election needs $3n - 1$ messages with an equal response
time.\\
Fault tolerance is low but can be improved by introducing techniques of fault
identification and ring reconstruction. Moreover, this algorithm verifies only the second condition of mutual exclusion.

\subsection{The bully algorithm} 
This algorithm has the same assumption of the \textit{circular ordering} one. Moreover, each process can communicate with processes having higher ID.
The messages exchanged are: election, answer and coordinator. It works as follows:
\begin{itemize}
	\item A process starts the election by sending an \textbf{election} message to all the processes with \textbf{higher} id, and waits for the reply.
	\item If the reply does not arrive within a timeout a coordinator is nominated
	(self-election!) and communicate the news to the other processes by
	sending a coordinator message to all the processes with lower id.
	\item Otherwise it waits for the arrival of a coordinator message and if it does not arrive, starts another election.
	\item A process that \textit{receives} a \textbf{coordinator message} saves the \# and consider that process the coordinator.
	\item A process that \textit{receives} an election message sends a reply to the sender and starts a new election, unless it has already done it, even if there is another coordinator.
\end{itemize}
\image{img/bullyAlgorithm}{Example of execution of Bully algorithm.}{1}
A process starts an election in the following cases:
\begin{itemize}
	\item When a process is reactivated after a fault, and if it has the higher id it becomes the new coordinator and let the other process know it even if there is another coordinator).
	\item When a process realizes that the coordinator does not answer.
	\item When a process receives an election message from a process with lower id.
\end{itemize}
The \textit{bully} algorithm has the following costs:
\begin{itemize}
	\item Worst case: $O(n^2)$ messages (Election starts from the lower id).
	\item Best case: $O(n-1)$ messages (Election starts from the process with higher id).
\end{itemize}
It verifies condition 2 (\textit{liveness}) but not condition 1 (\textit{safety}) in case in which the process is substituted by another one with the same id. There's also a problem of \textit{timeout} accuracy due to the use of synchronous communications.

\subsection{Deadlock management}
Deadlock could be a side effect of the \textbf{mutual exclusion}. It could happen because of:
\begin{itemize}
	\item \textbf{Resource allocation without pre-emption:} the system cannot force a process to release a resource.
	\item \textbf{Hold and wait:} a process that holds a resource keeps holding it (it blocks the resource) and can wait for another resource.
	\item \textbf{Circular waiting:} there exists a closed path in the allocation graph.
\end{itemize}
\image{img/deadlockConditions}{Deadlock conditions}{0.8}
There are different types of deadlock:
\begin{itemize}
	\item \textbf{Communication deadlock:} if the resource is a buffer.
	\item \textbf{Direct store and forward deadlock:} if it involves two nodes.
	\item \textbf{Indirect store and forward deadlock:} if it involves more than two nodes.
\end{itemize}
In order to manage the possible presence of deadlocks a \textbf{PAID} technique is used (Prevent - Avoid - Ignore - Detect):
\begin{itemize}
	\item \textbf{Prevention:} applied by:
		\begin{itemize}
			\item allowing only one resource allocation.
			\item pre-allocate resources before execution.
			\item resource allocation ordering.
			\item Age rule. 
		\end{itemize}
	\item \textbf{Avoidance:} It determines the stable states on the basis of the process needs (only if it's safe, it acquires the resources).
	\item \textbf{Ignoring:} applied to terminate processes in cyclic waiting.
	\item \textbf{Detection:} applying \textit{Chandy-Misra-Haas} algorithm:
		\begin{enumerate}
			\item A blocked process $P_1$ starts a test (structure composed of $ID_{\text{blocked process}}$, $ID_{\text{sending test process}}$ , $ID_{\text{receiving test process}}$).
			\item $P_2$ receives the test and, if it doesn’t need other resource, it stops the test. Otherwise, if it is blocked by $P_3$, it forwards the test.
			\item If a process receives a test with $ID_{\text{blocked process}} = ID_{\text{receiving test process}}$, it detects the deadlock.
		\end{enumerate}
	
\end{itemize} 
About \textit{deadlock removing}, it is possible to terminate processes that create it or performing a roll-back to consistent state.
