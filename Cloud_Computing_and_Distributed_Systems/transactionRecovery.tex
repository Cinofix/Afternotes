\subsection{Concurrency control for distributed transactions}
The servers apply to their own objects the protocols of concurrency control for
distributed transactions like \textbf{locking}, \textbf{optimistic} and \textbf{timestamp}. Servers must coordinate to ensure serial equivalence. This implies that if transaction $T$ is before transaction $U$ in their conflicting access to objects at one of the servers, then they must be in that order at all of the servers whose objects are accessed in a conflicting manner by both $T$ and $U$.

\paragraph*{Locking.} In a distributed transaction, the locks on an object are held locally (in the same server). The local lock manager can decide whether to grant a lock or make the requesting transaction wait.\\
When locking is used for concurrency control, the objects remain locked and are unavailable for other transactions during the atomic commit protocol. As lock managers in different servers set their locks independently of one another, it is possible that different servers may impose different orderings on transactions. These different orderings can lead to cyclic dependencies between transactions, giving rise to a \textbf{distributed deadlock} situation.

\paragraph*{Timestamp.} In distributed transactions, we require that each coordinator issues \textbf{globally unique timestamps}. A globally unique transaction \textit{timestamp} is issued to the client by the first coordinator accessed by a transaction. The transaction timestamp is passed to the coordinator at each server whose objects perform an operation in the transaction.\\
To achieve the same ordering at all the servers, the coordinators must agree as to the ordering of their timestamps. A \textit{timestamp} consists of a $<local\text{ }timestamp, server-id>$ pair. \\
When \textit{timestamp} ordering is used for concurrency control, conflicts are resolved with a possible abort.

\paragraph*{Optimistic.} With \textit{optimistic} concurrency control, each transaction is validated before it is allowed to \textit{commit}. Transaction numbers are assigned at the start of validation and transactions are serialized according to the order of the transaction numbers. A distributed transaction is validated by a collection of independent servers, each of which validates transactions that access its own objects. This validation takes place during the first phase of the \textit{two-phase commit protocol}.
\image{img/optimisticTable}{Example of commitment deadlock with optimistic concurrency control}{0.5}
As it is possible to see in the previous image, transactions access the objects in the order $T$ before $U$ at server $X$ and in the order $U$ before $T$ at server $Y$. Now if we suppose that $T$ and $U$ start validation at about the same time, but server $X$ validates $T$ first and server $Y$ validates $U$ first. 
From a previous rule of the validation protocol, we know that only one transaction may perform validation and update phases at a time. Therefore each server will be unable to validate the other transaction until the first one has completed. This is an example of \textbf{commitment deadlock}.
If parallel validation is used, transactions will not suffer from \textit{commitment deadlock}.

\subsection{Distributed deadlock}
Most deadlock detection schemes operate by finding cycles in the transaction \textit{wait-for graph}. In a distributed system involving multiple servers being accessed by multiple transactions, a global \textit{wait-for graph} can in theory be constructed from the local ones. There can be a cycle in the global \textit{wait-for graph} that is not in any single local one, there can be in fact a \textbf{distributed deadlock}. We can understand so that, to detect a \textit{distributed deadlock}, it is required to find a cycle in the global transaction \textit{wait-for graph} that is distributed among the servers that were involved in the transactions. An example of the \textit{global wait-for graph} is the following:
\image{img/distributedDeadlock}{Example of a global \textit{wait-for graph}}{0.6}
A simple solution is to use centralized deadlock detection, in which one server takes on the role of global deadlock detector. When it finds a cycle, it makes a decision on how to resolve the deadlock and tells the servers which transaction to abort. Centralized deadlock detection is not a good idea, because it depends on a single server to carry it out. It suffers from the usual problems associated with centralized solutions in distributed systems.

\paragraph*{Phantom deadlock.} A deadlock that is \textit{"detected"} but it is not really a deadlock is called a \textbf{phantom deadlock}. In a distributed deadlock detection, as the procedure will take some time, there is a chance that one of the transactions that holds a lock will meanwhile have released it, in which case the deadlock will no longer exist.

\paragraph*{Edge chasing.} A distributed approach to deadlock detection uses a technique called \textbf{edge chasing}. In this approach, the \textit{global wait-for graph} is not constructed, but each of the servers involved has knowledge about some of its edges. The servers attempt to find cycles by forwarding messages called \textbf{probes}, which follow the edges of the graph throughout the distributed system. A \textit{probe} message consists of transaction wait-for relationships representing a path in the \textit{global wait-for graph}.


\subsection{Transaction recovery}
The atomic property of transactions requires that all the effects of committed transactions and none of the effects of incomplete or aborted transactions are reflected in the objects they accessed. This property can be described in terms of two aspects: \textbf{durability} and \textbf{failure atomicity}. \textit{Durability} requires that objects are saved in permanent storage and will be available indefinitely thereafter. \textit{Failure atomicity} requires that effects of transactions are atomic even when the server crashes.\\
We will assume that when a server is running it keeps all of its objects in its volatile memory and records its committed objects in a \textbf{recovery file}. Therefore recovery consists of restoring the server with the latest committed versions of its objects from permanent storage.\\
The requirements for \textit{durability} and \textit{failure atomicity} are not really independent of one another and can be dealt with by a single mechanism, the \textbf{recovery manager}. The tasks of a \textbf{recovery manager} are:
\begin{itemize}
	\item To save objects in permanent storage (in a recovery file) for committed
	transactions.
	\item To restore the server’s objects after a crash.
	\item To reorganize the recovery file to improve the performance of recovery.
	\item To reclaim storage space (in the recovery file).
\end{itemize}
Any server that provides transactions needs to keep track of the objects accessed by clients’ transactions. At each server, an \textbf{intentions list} is recorded for all of its currently active transactions. An \textit{intentions list} of a particular transaction contains a list of the references and the values of all the objects that are altered by that transaction. When a transaction is committed, that transaction’s \textit{intentions list} is used to identify the objects it affected. Each object in the \textit{recovery file} is associated with a particular transaction by saving the intentions list in the
\textit{recovery file}. Following image shows a summary of the types of entry included in a \textit{recovery file}:
\begin{table}[H]
	\centering
	\begin{tabular}{| c | p{11cm} |}
		\hline
		\textbf{Type of entry} & \textbf{Description of contents of entry} \\ \hline
		\textbf{Object} & A value of an object. \\
		\hline
		\textbf{Transaction status} & Transaction identifier, transaction status (\textit{prepared}, \textit{committed}, \textit{aborted}) and other status values used for the two-phase commit protocol. \\
		\hline
		\textbf{Intentions list} & Transaction identifier and a sequence of intentions, each of which consists of \textit{<objectID, $p_i$>}, where $P_i$ is the position in the recovery of the value of the object.\\
		\hline
	\end{tabular}
	\caption{Types of entry in a recovery file.}
\end{table}
Two approaches can be used to create a \textit{recovery file}: \textbf{logging} and \textbf{shadow version}.

\subsubsection{Logging}
In the logging technique, the \textit{recovery file} represents a log containing the \textbf{history} of all the transactions performed by a server. The \textit{history} consists of values of objects, transaction status entries and transaction intentions lists. During the normal operation of a server, its recovery manager is called whenever a transaction prepares to commit, commits or aborts a transaction. When the server is prepared to commit a transaction, the recovery manager appends all the objects in its intentions list to the recovery file, followed by the current status of that transaction together with its intentions list. When a transaction is eventually committed or aborted, the recovery manager appends the corresponding status of the transaction to its recovery file. After a crash, any transaction that does not have a committed status in the log is aborted.
\par \bigskip \noindent
The below image illustrates the log mechanism for the banking service transactions $T$
and $U$. Entries to the left of the double line represent a snapshot of the values of $A$, $B$ and $C$ before transactions $T$ and $U$started. In this diagram, we use the names $A$, $B$ and $C$ as unique identifiers for objects.
We show the situation when transaction $T$ has committed and transaction $U$ has prepared
but not committed. When transaction $T$ prepares to commit, the values of objects $A$ and
$B$ are written at positions $P_1$ and $P_2$ in the log, followed by a prepared transaction status entry for $T$ with its intentions list $(< A, P_1 >, < B, P_2 >)$. When transaction $T$ commits, a committed transaction status entry for $T$ is put at position $P_4$. Then when transaction $U$ prepares to commit, the values of objects $C$ and $B$ are written at positions $P_5$ and $P_6$ in the log, followed by a prepared transaction status entry for $U$ with its intentions list $(< C, P_5 >, < B, P_6 >)$. Each transaction status entry contains a pointer to the position in the recovery file of the previous transaction status entry to enable the recovery manager to follow the transaction status entries in reverse order through the recovery file. The last pointer in the sequence of transaction status entries points to the checkpoint.
\image{img/loggingBank}{Example of log for banking service}{1}

\subsubsection{Shadow versions}
 The logging technique records transaction status entries, intentions lists and objects all in the same file: the \textbf{log}. The \textbf{shadow versions} technique is an alternative way to organize a recovery file. It uses a \textbf{map} to locate versions of the server’s objects in a file called a version store. The map associates the identifiers of the server’s objects with the positions of their current versions in the version store. The versions written by each transaction are \textit{"shadows"} of the previous committed versions.\\
When a transaction is prepared to commit, any of the objects changed by the transaction are appended to the version store, leaving the corresponding committed versions unchanged. These new as-yet-tentative versions are called shadow versions. When a transaction commits, a new map is made by copying the old map and entering the positions of the shadow versions. To complete the commit process, the new map replaces the old map.\\
To restore the objects when a server is replaced after a crash, its recovery manager reads the map and uses the information in the map to locate the objects in the version store. The below image illustrates this technique with the same example involving transactions $T$ and $U$. The first column in the table shows the map before transactions $T$ and $U$, when the balances of the accounts $A$, $B$ and $C$ are \$100, \$200 and \$300, respectively. The second column shows the map after transaction $T$ has committed.
\image{img/shadowVersions}{Example of log for banking service}{0.8}
The version store contains a checkpoint, followed by the versions of $A$ and $B$ at $P_1$
and $P_2$ made by transaction $T$. It also contains the shadow versions of $B$ and $C$ made by
transaction $U$, at $P_3$ and $P_4$.
The map must always be written to a well-known place so that it can be found when the system needs to
be recovered. The switch from the old map to the new map must be performed in a single atomic step.

\subsubsection{Recovery of the two-phase commit protocol}
The recovery management described previously, must be extended to deal with any transactions that are performing the \textit{two-phase commit protocol} at the time when a server fails. The recovery managers use two new status values for this purpose: \verb|done| and \verb|uncertain|. A \textbf{coordinator} uses committed to indicate that the outcome of the vote is \verb|Yes| and \verb|done| to indicate that the \textit{two-phase commit protocol} is complete. A participant uses \verb|uncertain| to indicate that it has voted
\verb|Yes| but does not yet know the outcome of the vote.\\
In \textbf{phase 1} of the protocol, when the \textit{coordinator} is prepared to commit, its recovery manager adds a coordinator entry to its recovery file. When it votes \verb|Yes|, its recovery manager records a participant entry and adds an \verb|uncertain| transaction status to its recovery file as a forced write. When a participant votes \verb|No|, it adds an \verb|abort| transaction status to its recovery file.\\
In phase 2 of the protocol, the recovery manager of the coordinator adds either a \textit{committed} or an \textit{aborted} transaction status to its recovery file, according to the decision.
\renewcommand{\arraystretch}{1.3}
\begin{table}[H]
	\centering
	\begin{tabular}{| p{2cm} | p{1.8cm} | p{10.8cm} |}
		\hline
		\textbf{Role} & \textbf{Status} & \textbf{Action of recovery manager} \\ \hline
		Coordinator & \textit{prepared} & No decision had been reached before the server failed. It sends \textit{abortTransaction} to all the servers in the participant list and adds the transaction status \textit{aborted} in its recovery file. Same action for state \textit{aborted}. If there is no participant list, the participants will eventually timeout and abort the transaction. \\
		\hline
		Coordinator & \textit{committed} & A decision to commit had been reached before the server failed. It sends a \textit{doCommit} to all the participants in its participant list (in case it had not done so before) and resumes the two-phase protocol at step 4. \\
		\hline
		Participant & \textit{committed} & The participant sends a \textit{haveCommitted} message to the coordinator (in case this was not done before it failed). This will allow the coordinator to discard information about this transaction at the next checkpoint.\\
		\hline
		Participant & \textit{uncertain} & The participant failed before it knew the outcome of the transaction. It cannot determine the status of the transaction until the coordinator informs it of the decision. It will send a \textit{getDecision} to the coordinator to determine the status of the transaction. When it receives the reply it will commit or abort accordingly. \\
		\hline
		Participant & \textit{prepared} & The participant has not yet voted and can abort the transaction. \\
		\hline
		Coordinator & \textit{done} & No action is required. \\
		\hline
	\end{tabular}
	\caption{Table for the different actions of the recovery manager.}
\end{table}