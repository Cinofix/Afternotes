\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[english]{isodate}
\usepackage[paper=a4paper]{geometry}
\newgeometry{top=3.5cm,bottom=2.5cm,right=2.5cm,left=2.5cm}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{fancyhdr}
\usepackage{framed}
\usepackage{lastpage}
\usepackage[hidelinks]{hyperref}
\usepackage{tabularx}
\usepackage[table]{xcolor}
\usepackage{enumitem}
\usepackage{mdwlist}
\usepackage{placeins}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{comment}
\usepackage{float}


\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DEFINIZIONI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\titolo}  {Afternotes}
\newcommand{\versione}{2.0}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SETUP DOCUMENTO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{cloud_computing_report_setup.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SEZIONI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\include{CCDS1-CCDS2}
\newpage

\include{CCDS3}

\newpage

\include{CCDS4}
\newpage
\include{CCDS5}



\section{Interprocess Communication}
Communication between processes is essential to allow them to cooperate and reach specific goals. Interprocess communication define how processes communicate inside the network. IPC can be implemented in different ways:
\begin{itemize}
	\item \textbf{Remote Procedure Call}, allowing a calling process to call a procedure in a remote node as if it is local. Provide maximum transparency, processes call remote procedures as they are local.
	\item \textbf{Remote Method Invocation}, remote objects are called with a remote invocation. It is necessary to maintain a remote interface to give information about what kind of methods the object offers and how remote processes can invoke them. Note that the caller global environment cannot be used as well as pointers for memory allocation.
	\item \textbf{Events}, asynchronous notification to objects of events. Indirect communication is defined as communication between entities in a distributed system through an intermediary with no direct coupling between the sender and the receiver(s).
\end{itemize}
RMI and RPC are analogous to the local method invocation and to the local procedure call, but with a different implementation.

\subsection{Transparency and Implementation}
One aspect that is very important for an \textit{IPC} is the level of transparency provided to the processes. The main goal is to call remote procedures as they are local. In this case RPC offers the maximum level of transparency, but it has some problems to distinguish local and remote procedure. The development of RPC and RMI includes:
\begin{itemize}
	\item \textbf{Marshalling},  the process of taking a collection of data items and assembling them into a form suitable for transmission in a message. In other words, it is a technique to codify parameters in order to be sure that the structure given to the procedure is preserved. This problem rises from the possibility of a computer system to represent data in different ways. \textit{Marshalling} codify parameters to transform them into a common representation, improving reliability and performance.
	\item \textbf{Invocation semantic}, determines what kind of semantic is given to the processes.
	\item \textbf{Binding}, strategy to identify and connect to the server. It can be \textit{\textbf{static}}, decided a priori how to reach the server, or \textit{\textbf{dynamic}}, discovers where is the server dynamically. The first one is faster since there is a direct communication to the server but the second one offers an high level of location transparency.
\end{itemize}

The \textbf{Middleware} provides transparency, the procedures call are used in same way if they are local or remote. It supports implementation for RPC and RMI and if the middleware allows different programming languages, it usually specifies the final notation using an \textbf{Interface Definition Language} (IDL).
\textbf{Interfaces} are implemented in order to make the operations transparent, programs are organized in a set of modules that cooperate. The interface has only the information needed for available methods and it doesn't define the final implementation.\\
Two essential modules for RPC are:
\begin{itemize}
	\item \textbf{Client stub}, used to catch the request and to translate it into a remote action.
	\item \textbf{Server stub}, receives the request, selects the right procedure, execute it and return possible results to the client.
\end{itemize}

\subsection{Object Oriented Model}
RMI is based on the \textbf{Object Orient Model} (\textit{OOM}), in which components are called objects. An object is an entity that contains set of data and methods that define its behavior. From an implementation point of view an \textit{OOM} offers:
\begin{itemize}
	\item \textbf{Reference to object}, it is an alternative identifier for an object. Objects can be passed as arguments or obtained as results.
	\item \textbf{Interface}, it defines methods and how to use them but it doesn't specify how they are implemented.
	\item \textbf{Methods}, operations that define the behavior of objects of the same class. They can be invoked from external objects. 
\end{itemize}
Usually Object Oriented Programming languages are supported by an entity called \textit{Garbage Collector}, used to recovery memory space of objects that are not referenced.
\image{img/oopInvocation}{Remote and local invocation methods}{0.75}
On the previous picture we can see an example of interaction using remote and local methods. 
\begin{enumerate}
	\item Object A invokes a remote invocation to object B, since it is out of the environment of A.
	\item Later B invokes local methods of C and D.
	\item At the end E applies a remote invocation to a method of F, since they are inside the same system but in different environments.
\end{enumerate}
  
\subsection{Invocation Semantics}
Remote procedure calls provides a range of invocation semantics that specify the implementation of the invocation of the protocol \textbf{Request-Reply}. Invocation semantics are defined in base of different implementation choices considering: 
\begin{itemize}
	\item Retransmission of the request.
	\item Duplicate filtering in the server in case of re transmission.
	\item At arrival of a retransmitted request: re-execution or re-send of results.
\end{itemize} 
There can be different types of \textbf{call semantic}, referring to the reliability of the RPC or RMI from the caller point of view. Local operations guarantee \textit{Exactly Once} semantic, since the caller knows that the request will be sended and executed exactly once.
\image{img/callSemantic.png}{Invocation Semantic}{1}
\begin{itemize}
	\item \textbf{Maybe}, the request is sent only once independently of the fact that the client receives a reply or not. There is no fault tolerance measure, there might be loss of the invocation or the result or crashing of the server. The client doesn't know if the RMI o RPC has been successful or not.
	\item \textbf{At least once}, there is re-transmission until the client doesn't get a reply. There might be possible duplicate executions. It can be used only for \textbf{\textit{idempotent}} operations, which return the same result at every execution and that don't produce any change of state.
	\item \textbf{At most once}, there is retransmission until the client doesn't get a reply, but the server remembers the operations already executed and don't replay the same operations. The server maintains an history table in which stores client id and operations executed for him. When a request arrives to the server it verifies if the request has already been performed for the same client, and in case of positive answer, it returns the result without replay the execution. For this reason operations for this semantic are called \textit{\textbf{non-idempotent}}, since each time they are executed, they produce a change of state inside the server.\\
	At \textit{most once} semantic must solve the problem of deciding how big is the history table and when remove an entry.
\end{itemize}

\subsection{RMI and RPC implementations}
RPC and RMI are very similar, the choice of adopting one of them essentially regards the programming language adopted, for instance oop languages (like Java) tend to adopt RMI. In this section we want to focus our attention on how this two techniques are implemented and which are the modules that interact.
\subsubsection{RMI}
The structure of an RMI communication system is composed by different modules that interact to reach the final goal:
\begin{itemize}
	\item \textbf{Communication module}, it is responsible for providing a specified invocation semantic. There are 2 communication modules, one inside the client environment and the other one inside the server environment. The two components carry out the request-reply protocol between client and server, specifying the message type, the request and the remote reference of the object to be invoked. 
	\item \textbf{Remote reference module}, it is responsible for the translation between local and remote object references and for creating remote object references. It contains a \textbf{remote object table} that records the correspondence between local object references in that process and remote object references.
	\item \textbf{Proxy}, it makes remote method invocation transparent to the client, that sees the invocation as if it were local. It is also responsible for marshalling and un-marshalling.
	\item \textbf{Dispatcher}, it is defined inside the server. When it receives a request message from the communication module, it selects the appropriate method in the skeleton required by the request.
	\item \textbf{Skeleton}, it implements the methods in the remote interface.
\end{itemize}
\image{img/rmiImplementation}{Internal implementation of RMI}{0.8}


\subsubsection{RPC}
The structure of an RPC communication system is composed by different components that interact to reach the final goal:
\begin{itemize}
	\item \textbf{Stub}, its main role is to make transparent the remote call and execute marshalling. There are two kinds of stubs: \textbf{server stub} and \textbf{client stub}. \textit{Client stub} makes transparent the remote call and execute marshalling, instead \textit{server stub} applies un-marshalling and execute the service procedure required.
	\item \textbf{Dispatcher}, it opens the request message and it selects the procedure correspond to the request.
\end{itemize}

\image{img/rpcImplementation}{Internal implementation of RPC}{0.7}

\subsection{Callback}
In some cases a client can send continuous requests to the server and in this way the transmission delay and waiting time have a strong effect to the performance.\\ 
\textit{Request-Reply} protocol is not ideal. A possible solution is to \textit{reverse the interaction}: server notifies the client when it's available. The client sends a remote object containing a methods that the server can invoke. The server keeps a list of records containing clients and their requests. When an \textbf{event} occurs the server calls all the interested clients. The advantage of using this approach is that it avoids repeated calls from the clients that increase the performances, but on the other hand, the drawback is that the server has to keep a list of the interested clients and realize RMI to all the callback in the list. Regarding to the indirect communication there isn't an event space.
\image{img/callback.png}{RMI Callback}{0.7}

\section{Interprocess Communication - Implementation \& Design}
Communication inside distributed systems can be carried out using different implementations. There are many possible kinds of communication, we will illustrate so the three most important. We will deal with:
\begin{itemize}
	\item \textbf{Socket}, creates, at low level, a channel between processes on different hosts. For each application it is necessary to define protocol for data coding and decoding. This solution lacks of transparency.
	\item \textbf{Remote Procedure Call} or \textbf{RPC} allows client programs to call procedures transparently in server programs running in separate processes and generally in different computers from the client.
	\item \textbf{Remote Method Invocation} or \textbf{RMI}  allows an application running on a local machine to invoke the methods of another application running on a remote machine. Locally only a \textbf{remote object reference} (\textit{Object callback}) is created, that is actually active on a different host. A program invokes methods through such a local reference. All the invocations of the methods to be transmitted are handled by the \textbf{Object Request Broker} (\textit{ORB}).
\end{itemize}
Middleware provides transparency to the interprocess communication. It is above the transport layer adopted from the network and it gives a interface to the upper levels providing transparency on the protocol adopted (TCP or UDP).

\begin{itemize}
	\item \textbf{UDP} represents a datagram communication so without ordering and reliability. Interface to \textit{UDP} is based on \textbf{message passing} and to enable sending a \textbf{single message} from sender to receiver. It uses an \textbf{unreliable} communication which is based on a \textit{not blocking send} and a \textit{blocking receive} with possible timeouts.\\
	With UDP there can be different types of \textbf{faults} like: \textit{omission} (loss of messages, $\dots$), and \textit{arbitrary} (unordered delivery). It can be useful for applications that don't require strong reliability (like DNS).
	\item \textbf{TCP} opens a stream communication. From its nature TCP doesn't provide location transparency since client has to specify IP address and port number of the server, but a solution can be the usage of a name server.\\
	Interface to \textit{TCP} is based on \textbf{bidirectional stream} and to enable sending a \textbf{stream of data} between sender and receiver. It is based on \textbf{producer-consumer} communication.\\
	With TCP there can be different types of \textbf{faults} like: possible block of due to the \textit{buffer} of the destination socket, control of the \textit{correctness}, \textit{duplication} and \textit{ordering}, control of the \textit{message loss}.
\end{itemize}
\image{img/sockets}{Sockets and ports}{0.7}
Possible faults can occur in different cases respect to UDP. Possible block due to the buffer of the destination socket, duplicate, ordering, correctness or message loss. Furthermore, it is impossible to distinguish network and destination process fault. 

\section{Request-Reply communication}
When we are dealing with client-server architecture, the form of \textbf{request-reply} communication is supported. In this type of communication, client and server exchange messages, described as \textit{send} and \textit{receive} operations, which can be datagrams if using UDP, streams for TCP.
\image{img/req-rep}{Request-Reply communication}{0.8}

\subsection{Primitives} 
The request-reply protocol is composed by the following \textit{primitives}:
\begin{itemize}
	\item \textit{doOperation}
	\item \textit{getRequest}
	\item \textit{sendReply}
\end{itemize}
The way in which this 3 functions are implemented correspond to the choice of a specific semantic provided by the communication system.
 
The method \textit{doOperation} is used by clients to invoke remote operations, specifying the server and the operation needed to be executed. The client is usually blocked until the server performs the requested operation since this type of communication is \textbf{synchronous} in the normal case. Asynchronous request-reply communication is rare, but it can exists, and it might be useful in situations where clients are allowed to retrieve replies later. The method \textit{getRequest} is used by the server process to receive requests. The server will reply to the client using \textit{sendReply} method when it has finished to invoke the requested operation. The client which receives the reply from the server is unblocked.\\

The information to be transmitted in a request message or a reply message is shown in the figure below:
\image{img/message-structure}{Request-Reply message structure.}{0.8}
The first field indicates the type of the message, if it's a request or a reply message. \textit{requestId} is the message identifier. The \textit{doOperation} method generates a \textit{requestId} for each message and the server remembers these identifiers. The third field is a remote reference, and the fourth field is an identifier for the operation to be invoked.\\

Notice that in request-reply communication each message have a \textbf{unique message identifier} by which it may be referenced. This message identifier is composed by a  \textit{requestId} which is a sequence of integers, and
an \textit{identifier} for the sender process, to be unique in the distributed system.

\subsection{Reliability and Faults in Request-Reply}
So far we have seen the basic characteristics of the request-reply communication protocols, but we also can consider additional properties such as \textit{reliability} of the message delivering. \\

In particular, if the primitives are implemented over UDP protocol, they suffer from:
\begin{itemize}
	\item Order of delivering not guaranteed
	\item Loss of messages
	\item Process failures
\end{itemize}

In order to cope with these problems, \textit{doOperation} can use a \textbf{timeout}, when the client is waiting for the server's reply. After a timeout, \textit{doOperation} sends the request message repeatedly until either it gets a reply or it is sure that the delay is due to lack of response from the server rather than to lost messages. When the server receives several request messages as it happens using the \textit{timeout}, it should recognize multiple messages with the same request identifier and filter out the duplicates.\\

Another problem can be the \textbf{re-execution} of the operations: if the reply from the server has been lost, the server should execute the operation again to obtain the result unless it has stored the interested result. An \textit{idempotent} operation could be useful in these cases. Otherwise, the \textbf{history} of transmitted reply messages can be maintained. The problem of maintaining the history table is that it can occupy the memory: in order to deal with this problem, the client can make only one request at a time, so the server can interpret each request as acknowledgement of its previous reply, so the history need to contain only the last reply message sent to each client. However periodically the messages in the history are discarded after a period of time, because the client process can terminate and does not send the acknowledgement.

\subsection{Remote procedure call}
In RPC, procedures on remote machines can be called as if they are procedures in the local address space. In particular \textit{Interface definition languages} (IDLs) are designed to allow procedures implemented in different languages to invoke one another. An IDL provides a notation for defining interfaces in which each of the parameters of an operation may be described as for input or output in addition to having its type specified.\\

The primitives of request-reply protocols can be implemented in different ways to provide different delivery guarantees:
\begin{itemize}
	\item \textit{Retry request message}: asking to retransmit the request message until either a reply is received or the server reasonably considered failed.
	\item \textit{Duplicate filtering}: filtering out duplicate requests at the server.
	\item \textit{Retransmission of results}: keeping a history of result messages to enable lost results to be retransmitted without re-executing the operations at the server.
\end{itemize}

\subsubsection{Semantics of RPC}
First of all, we say that the termination is \textbf{normal} when the client receives the message from the server. The termination is considered \textbf{abnormal} if the client does not receive the reply.

\begin{itemize}
	\item \textbf{Maybe semantics}: RPC may be executed once or not at all. If the result message has not been received after a timeout and there are no retries, it is uncertain whether the procedure has been executed. Maybe semantics is useful only for applications in which occasional failed calls are acceptable.
	\item \textbf{At least once semantics}: it is achieved by the retransmission of request messages as idempotent operation. The client calls with timeout, and if the answer has not arrived yet, it tries again repeating the attempts a finite number of times. The server executes the received calls and sends the answers, but it does not keep the state of previous calls.
	\item \textbf{At most once semantics}: it is achieved by retries masking any omission falures of the requests. The messages contain a call sequence number. The server keeps the results of the last call executed with sequence number for each request and it checks whether it is a new one. Only in this case executes it, otherwise it sends the already computed result.
\end{itemize}

\subsubsection{RPC fault management and semantics}
The faults can be classified into two main cathegories:
\begin{itemize}
	\item \textbf{Communication}: working processes can not be able to communicate temporarly.
	\item \textbf{Node crash}: possible recovers, we should build the correct semantics.
\end{itemize}

In particular, the possible faults are the following:
\begin{itemize}
	\item the cannot locate the server process
	\item loss of the client request message
	\item loss of the reply of the server
	\item server crash during the call
	\item client crash during the call
\end{itemize}

We can try to distinguish the several situations in which the client sends the request then the timeout reaches the deadline while it waits for the answer:
\begin{itemize}
	\item if the client does not try again: semantics RPC is \textit{maybe}.
	\item if the client tries until it gets a reply and the answer is AU, the call has \textit{abnormal termination} with RPC semantics is \textit{exactly once}.
	\item if the client tries until it gets a reply and the answer is the reply, if the server has no memory of previous execution, the server can execute the duplicated requests and so RPC semantics is \textit{at least once}.
	\item if the server keeps the result of the last execution in a buffer, in case of duplicated requests it is detected and it sends again
	the result; RPC semantics is \textit{at most once}.
\end{itemize}

Furthermore we should distinguish the two types of crashes: \textit{during or after the execution} or \textit{before} the execution. In any case, if the server crashes, with \textit{exactly once semantics} we would have normal termination with one execution, abnormal termination with no execution. This type of semantics rises the problem of inconsistency between the client and server. Atomic transaction or implement the RPC \textit{at most once} can be thought as a solution to this problem.
\image{img/semanticsRPC.png}{RPC semantics}{0.7}

\subsubsection{RPC semantics and server crash}
Crashing of server can happen during or after the execution phase, and this is totally transparent to the client. The unique information that it has is the fact that the timeout occurs.
\textbf{Semantics exactly} once is very difficult to reach on a distributed system, it has to satisfy the behavior "all or nothing". Meaning that in case of normal termination the request is executed only once, otherwise in case of abnormal termination no execution of the request. In presence of server crash provide exactly once semantic it is necessary to use \textbf{atomic actions},  which allow client and server to coordinate their action in order to guarantee "all or nothing" property. But this approach is not practicable, and what is essentially done is to implement \textbf{at most once semantic}.

Summary of the two semantics:

\begin{itemize}
	\item \textbf{At least once RPC}
	\begin{itemize}
		\item \verb|client|, sends request setting a timeout. If the timeout is over try again until it receives an answer or for a finite number of times.
		\item \verb|server|, executes the received call and sends the answer. It does not keep memory of the previous calls.
	\end{itemize}
	
	
	\item \textbf{At most once RPC}
	\begin{itemize}
		\item \verb|client|, sends request setting a timeout. If the timeout is over try again until it receives an answer or for a finite number of times.
		\item \verb|server|, it store an history of the last call for each client. For each request checks whether it is a new one and only in this case executes it, otherwise it sends the previous computed result. Only in case of crash of the server this state is loss.
	\end{itemize}
\end{itemize}


\section{Multicast communication}
Communication can be defined not only for one-to-one, but there other two possible cases:
\begin{itemize}
	\item \textbf{broadcast}, consists on a one-to-all communication system. A process send the message to all the other processes. Primitives are designed to send the message to all the processes.
	\item \textbf{multicast}, consists on a one-to-many communication system. A process send the message to a specific group of processes. Primitives are designed to send the message to set of receivers.
\end{itemize}
Multicast communication is very frequent and there are different motivations:
\begin{itemize}
	\item \textbf{fault tolerance - service replication}, since the request is sent to a set of servers in parallel if one of them crash the other can reply to the request. So it is tolerant to server crashing.
	\item \textbf{replication of data}, data can be replicated in different servers.
	\item \textbf{performance}, the request can be executed by a group of servers in parallel. This approach improves the performance of the system. For instance the update of several copies of different files can be performed by a specific group.
\end{itemize}

Multicast communication brings also some issues for which it is necessary to design a strategy for managing them. For instance, sender send a request to a group of servers and how it has to deal the answer? There can be different strategies: no wait, wait only for one answer, wait for some answer (how many?) or wait for all answers. 
\image{img/multicast.png}{Multicast}{0.6}

\subsection{Atomicity and Reliability}
Multicast communication can also provide two different properties:
\begin{itemize}
	\item \textbf{Atomicity}, there is the guarantee that all the components inside the group receive the message. It is received by all or none.
	\item \textbf{Reliability}, the delivery is guarantee.
\end{itemize}
An \textbf{unreliable} multicast communication system sends only once the message. It is also available the combinations: atomic and unreliable, since if one of servers does not receive the message the others discard the message.

\subsection{Multicast protocols: ordering} 
Another important issue for multicast protocol is ordering, messages are transmitted to a group in multicast arrive to each component of the group according to the sending order.
Consider the following figure:
\image{img/multicast-ordering.png}{Message ordering}{0.4}
$A$ and $B$ are two events sent by two different senders and $A$ is sent before $B$. Ordering problem consists to develop a strategy that ensures that receivers receive the two messages with the same order.
Single atomic multicast keep the FCFS order of the messages, so when there is only one sender the order is guaranteed, instead considering if there are multiple senders this strategy doesn't ensure the order.

Some strategies are considered to solve this problem:
\begin{itemize}
	\item \textbf{FIFO ordering}, FIFO ordering is concerned with preserving the order from the perspective of a sender process. If a process sends one message before another, it will be delivered in
	this order at all processes in the group.
	\item \textbf{Causal ordering}, it considers a logical ordering, called also casual, and the messages are delivered considering that constraint. If an event $A$ precedes an event $B$ then the messages are delivered according to that order.
\end{itemize}
In a \textbf{totally ordering multicast} if a message is delivered before another message at one process, then the same order will be preserved at all processes.

\subsection{Multicast protocols: implementation}
Multicast can be supported by different types of implementations of the two primitives: \verb!send! and \verb!receive!. The way in which they are implemented define the characteristics of the multicast system.
On the following figure we can see a basic implementation of \verb!send! primitive, not reliable and atomic.
\image{img/implementation}{Basic send procedure}{0.5}
For a reliable multicast is necessary to check possible loss of messages, crashing of sender, wait the answer and also consider possible retransmission in case of time-out.
The implementation have also to consider the occurrence of faults like message omission an sender crash. A possible solution is to use a monitor with the following roles:
\begin{itemize}
	\item check the current transmission
	\item manage possible retransmission
	\item remove crashed processes, if a process is waiting for an ack but the server crashed it will wait for ever.
	\item notifies the group’s components when a process is added, or when a process is excluded.
\end{itemize}

\subsection{Reliability and Atomicity}
Atomicity and reliability bring with them a non indifferent cost since:
\begin{itemize}
	\item \textit{sender} sends the message to the group and waits for the ack from all the components inside the group.
	\item if all the ack arrive it'ok, otherwise if they do not arrive within a timeout it is necessary to re-transmit the message.
\end{itemize}
Another problem for atomicity regards the management of sender fault. In this case to preserve atomicity every destination process sends an ack and wait for confirm, the sender once the multicast is completed sends back to confirm to everyone. But this solution is not so efficient, and so we can consider \textbf{Hold-back queue} as alternative.

With \textbf{Hold-back queue} the destination keep the message suspended before delivery, up to the arrival of the confirm. In order to guarantee the ordering and atomicity the messages are numbered and every message is delayed until the previous ones arrive.
\image{img/holdbackqueue.png}{Hold-Back queue}{0.7}

Another solution consists to the usage of \textbf{negative ack}, the messages are numbered according to the order from the server and the destination process sends a \textbf{NACK} if the message number of the arrival is not in the order of the sequence. The destination process does not send the \textbf{ACK} and the sender has a copy (history) of the sent messages.
But using only ack is difficult to understand when it's time to clear the history, so occasionally destination processes send positive ack with number of received message using piggybacking technique.

\subsection{Atomic and totally ordered multicast}
In order to guarantee atomicity and totally order each process is associated with a unique \textit{totally ordered identifier}. A message is \textbf{stable} in the destination if other messages with smaller identifier cannot arrive. Destination pass to upper levels (application) only stable messages. This solution is easy to implement if sender and receivers agree with a \textbf{shared identifier sequence} used to assign identifier to the messages. In order to decide this sequence some solutions are proposed:
\begin{itemize}
	\item using a timestamp from physical or logical clock
	\item using a sequencer process
	\item using a protocol among the group processes to generate an identifier
\end{itemize}
Regarding the implementation it can defined:
\begin{itemize}
	\item \textbf{centralized}, unique manager that makes the ordering. But the drawback is that it can became a bottleneck since all the request should pass from him.
	\item \textbf{distributed}, coordination of the receivers that makes an agreement on the ordering. In general what is adopted in this case is the usage of distributed algorithms.
\end{itemize}
\image{img/ipMulticast}{IP multicast communication}{0.5}


\section{Event notification}
In general we refer to objects that want to receive information and be notified by an event for which it is subscribed. This approach introduces a new paradigm called \textbf{publish-subscribe}.

\image{img/eventNotification.png}{Eventi notification}{0.7}

A publish-subscribe system is a system where publishers publish structured events to an event service and subscribers express interest in particular events through subscriptions which can be arbitrary patterns over the structured events. For example, a subscriber could express an interest in all events related to this textbook, such as the availability of a new edition or updates to the related web site. The task of the publish-subscribe system is to match subscriptions against published events and ensure the correct delivery of event notifications. A given event will be delivered to potentially many subscribers, and hence publish-subscribe is fundamentally a one-to-many communications paradigm.
In other words: an object generates events and publishes the type of event that can be notified, and another one that wants to receive \textbf{notifications} executes a subscribe to the event types of interest. 
This approach preserve heterogeneity since publisher can assume different types and events can be with different types. It is commonly adopted by \textit{asynchronous systems}, and it is different from callback since the last one is a one-to-one communication sistem, instead in event notification more than one objects can be interested on a particular event and all of them receive a notification when it occurs.

\image{img/eventNotification_full.png}{Eventi notification}{0.7}

Two fundamental characteristics of publish-subscribe systems are:
\begin{itemize}
	\item \textbf{Heterogeneity}, event-generating objects publish the types of events they offer, and that other objects subscribe and provide an interface for receiving and dealing with the resultant notifications.
	\item \textbf{Asynchronicity}, notifications are sent asynchronously by event-generating publishers to all the subscribers that have expressed an interest in them to prevent publishers needing to synchronize with subscribers – publishers and subscribers need to be decoupled.
\end{itemize}  

\subsection{Event service}
\textbf{Event service} is a service that manages the event space, for which the main goal is to keep publisher and subscriber independent. Publisher uses event service to produce events and subscriber uses it to specify the event of interest in order to receive the notification.
Event service maintain a database of published events and of interest.
\image{img/eventService.png}{Event service}{0.7}
Notification can be modeled considering different solutions:
\begin{itemize}
	\item \textbf{Direct notification}, notification is performed directly by the object of interest to the subscriber, no overhead is introduced. The drawback is that when there are a lot of  subscribers there is an huge overhead inside event space. 
	\item \textbf{Notification via observer}, use another entity called \textbf{observer} for managing the notification. There can be adopted more than one observers and for each observer is associated a set of subscriber as a hierarchical system. This solution improves scalability, fault management and in terms of performance each observer has a local queue of notifications, instead of using a unique one like direct communication. This solution is also the best one in terms of security since there is no direct communication with the object and the object of interest is inside the local environment.
	\item \textbf{Notification via observer with external object}, observer time to time ask if the event is done. Scalability, many object of interest for the same observer.
\end{itemize}
\image{img/notificationModel.png}{Notification models}{0.7}
The observer can implement different functionalities:
\begin{itemize}
	\item \textbf{forward observer}, deliver notification from different objects.
	\item \textbf{filtering}, reduce the number of notification received from an observer.
	\item \textbf{event model}, interest to specific relations among events.
	\item \textbf{mailbox}, introduces a delay in the notification delivery when the subscriber is not ready. This technique is useful to improve fault management.
	\item \textbf{Priority}, observer can manage priority for notification.
\end{itemize}


\include{CCDS9}


\section{Coordination and synchronization: clock}
Time is an important and interesting issue in distributed systems, for several
reasons. First of all, time is a quantity we often want to measure accurately. In order to know at what time of day a particular event occurred at a particular computer it is necessary to synchronize its clock with an authoritative, external source of time.
Second, algorithms that depend upon \textbf{clock synchronization} have been developed for several problems in distribution. These include maintaining the consistency of distributed data, authentication protocols, eliminating the processing of duplicate updates, ordering events and serialization of transactions.
In distributed systems there's no \textbf{global physical clock}, meaning that there can be skew between computer clocks on the same network. In order to provide clock synchronization different algorithms are designed.\\
These algorithms can be developed considering \textbf{physical clocks} and \textbf{logical clocks}.

\subsection{Model definition}
Considering the following example that, for assumption, communicates using message passing.
\image{img/clocks.png}{Clocks}{0.5}
There are $N$ processes $p_1, p_2,...,p_N$ connected in a network. Each process has a \textbf{local clock} and there is no shared memory, they can communicate only using message passing.\\
We define ordering with the following notation:
$$e \rightarrow_i e^\prime \qquad \text{if the event e occurs before } e^\prime \text{ in process } p_i$$
$$h = <e_i^0, e_i^1,...> \qquad \text{state history of process i}$$
Where the \textbf{history} represents the sequence of events that take place on the process.

\subsection{Physical clock}
Synchronization algorithms based on \textbf{physical clocks} operate using local clock of each process.
With the notation $C_i(t)$ we define the local clock of process $p_i$ at physical time $t$. It is commonly used to consider the timestamp, time indicating when the event occurs.
Two events are successive only if the clock resolution (the time between two successive updates of the clock value) is less than the time interval between the two successive events. For example: if the local clock consider only minutes all the events occurring between $0 < t < 60$ have the same arrival time.
Different local clock can have different values, and it is possible to define:
\begin{itemize}
	\item \textbf{Skew}, difference between two clocks.
	\item \textbf{Drift rate}, frequency of the local clock is different from an ideal one.
\end{itemize}
A possible idea consists to synchronize local clocks with the \textit{UTC} (Coordinated Universal Time), which provides the real time of the earth.
Synchronization can be:
\begin{itemize}
	\item \textbf{external}, if it is forced by external agents.
	Formally speaking:
	$$|S(t) - C_i(t)| < D	\qquad 1 \leq i \leq N \qquad \forall \in I$$
	Where $S(t)$ is the real time (provided for instance by UTC), $D$ is the precision and $I$ is the interval of synchronization. This procedure synchronizes the clock of each process $i$ with precision $D$ from the real time.
	
 	\item \textbf{internal}, if there is an agreement among a set of processes.	Formally speaking:
 	$$|C_i(t) - C_j(t)| < D	\qquad 1 \leq i \leq N \qquad \forall \in I$$
 	All the clocks are synchronized with precision $D$.
\end{itemize}
\image{img/synchIntExt.png}{External and Internal synchronization}{1}

A physical clock $H$ is correct if the drift is within a given threshold $\rho > 0$. Formal definition:\\
Given $t,t^\prime \quad$ if $t^\prime > t\quad$ then $\qquad(1-\rho)(t^\prime - t) \leq H(t^\prime) - H(t) \leq (1+ \rho)(t^\prime - t)$.
A clock $C$ is defined as \textbf{monotone} if it only goes on forward. 
Some events can break monotonicity of a clock, just to give an idea, recovery procedure set the current time to a previous time. \\

From the physical clock we can define also software clock which is given by: $$C_i(t) = aH_i(t)+b \qquad \qquad \text{a,b constants}$$.
\image{img/clockDeviance.png}{Clock deviance from real time}{0.5}

\subsubsection{Clock synchronization algorithm: Distributed synchronous system}
We begin by considering the simplest possible case: synchronization between processes in a synchronous system. In a \textbf{synchronous system}, bounds are known for the\textit{ drift rate} of clocks, the \textit{maximum message transmission delay}, and the time required to execute each step of a process. One process sends the time t on its local clock to the other in a message m. In principle, the receiving process could set its clock to the time $t + T_{com}$, where $T_{com}$ is the time taken to transmit $m$ between them. The two clocks would then agree since the aim is internal synchronization, it does not consider external synchronization with UTC.
\image{img/clockSyncInSyncSystem.png}{Clock synchronization: Sync. System}{0.7}
On this image we have two processes $p$ and $p^\prime$ that want to communicate using message passing. $p$ sends a message with the local clock $t$ and $p^\prime$ receives the message and sets its own local clock to $t+T_{com}$.
From a distributed synchronous system we know that:
\begin{itemize}
	\item There is always a \textbf{minimum transmission time}, $T_{min}$, that would be obtained if no other processes executed and no other network traffic existed. It can be measured or conservatively estimated.
	\item In a synchronous system, by definition, there is also an upper bound max $T_{max}$ on the time taken to transmit any message.
\end{itemize}
From these results some possible choice can be discussed to determine the threshold $T_{com}$:
\begin{itemize}
	\item set $T_{com}$ threshold equal to $T_{max}$ or $T_{min}$, with possible \textbf{shew error} equal to: $$\text{error} \leq \Delta = (T_{max} - T_{min})$$
	\item set $T_{com}$ threshold equal to $(T_{max} + T_{min})/2$, with possible \textbf{shew error} equal to: $$\text{error} \leq \frac{\Delta}{2}$$
\end{itemize}
In general from a better analysis it is possible to say that for a synchronous system, the optimum bound that can be achieved on clock skew when synchronizing $N$ clocks is $\Delta(1 -1/N)$.


\subsubsection{Clock synchronization algorithm: Cristian}
Most distributed systems found in practice are \textbf{asynchronous}: meaning that message delays are not bounded and there is no maximum bound on message transmission delays. For an asynchronous system, we can only say only that $T_{com} = min + x$ , where $x > 0$ and it is not known in a particular case.
Some algorithms are designed in order to implement clock synchronization for asynchronous systems. The first one was given by \textbf{Cristian}, in 1989, which suggested the usage of a \textbf{time server}, connected to a device that receives signals from a source of UTC, to synchronize computers externally. 
\image{img/cristianAlg.png}{Cristian Algorithm}{0.7}
Every machine periodically asks for the time to the time server and when it receives the reply:
\begin{itemize}
	\item It checks the clock.
	\item It computes the network delay (at least $T_{min}$) as $T_{round}$, round trip time.
	\item It sets the clock to $t+ T_{round}/2$.
\end{itemize}
From the point of view of the time server when it receives a time request the server puts the time $t$ in the reply message just at the last moment useful for sending.
The precision $D$ given by this technique is equal to $\pm (T_{round}/2 - T_{min})$.

This algorithms works well when synchronization delay is close to zero. But in any case it has some drawbacks like: the usage of a central server reduces and limits reliability and performance, or malicious interference of the clients. Some aspects can be improved for example using multicast instead of using a single and central server or introduce authentication technique for the clients.

\subsubsection{Clock synchronization algorithm: Berkeley}
Another interesting algorithm for clock synchronization in asynchronous systems is called \textbf{Berkeley}. Berkeley uses a coordinator computer as the master, also called \textbf{active time server}. Unlike in Cristian’s protocol, this server periodically polls the other computers whose clocks are to be synchronized, called \textbf{slaves}. The slaves send back their clock values to it. The master estimates their local
clock times by observing the round-trip times (similarly to Cristian’s technique), and it averages the values obtained (including its own clock’s reading). The coordinator indicates who has to speed-up or speed-down the clock using the average value. The idea is that this average cancels out the individual clocks’ tendencies to run fast or slow. The master eliminates any occasional readings associated with larger times than this maximum.

Instead of sending the updated current time back to the other computers – which would introduce further uncertainty due to the message transmission time – the master sends the amount by which each individual slave’s clock requires adjustment. This can be a positive or negative value.

The Berkeley algorithm eliminates readings from \textbf{faulty clocks}. Such clocks could have a significant adverse effect if an ordinary average was taken so instead the master takes a \textbf{fault-tolerant average}. That is, a subset is chosen of clocks that do not differ from one another by more than a specified amount, and the average is taken of readings from only these clocks. In other words, the average does not consider the times too far or with abnormal values, meaning that is more \textbf{fault-tolerant} than a simple average. 

But as Cristian's algorithm Berkeley uses a central server that limits reliability and performance of the entire system.

\subsubsection{Clock synchronization algorithm: NPT}
Cristian and Berkeley algorithm are based on the usage of a centralized system, which limits some properties of the entire system. Another approach is given by \textbf{distributed algorithms}.
The \textbf{Network Time Protocol} (NTP) defines an architecture for a \textit{time service} and a protocol to distribute time information over the Internet. NTP provides:
\begin{itemize}
	\item synchronization of the physical clocks respect to UTC for all the clients inside the network.
	\item \textbf{reliable} service that is fault tolerant to connection loss. Fault tolerance is given by redundancy of server and path.The servers can reconfigure so as to continue to provide the service if one of them becomes unreachable.
	\item \textbf{scalability}, allows frequent synchronization also in presence of many nodes.
	\item To provide protection against interference with the time service, whether malicious or accidental: The time service uses authentication techniques to check that timing data originate from the claimed trusted sources. It also validates the return addresses of messages sent to it.
\end{itemize}

The NTP service is provided by a network of servers located across the network. \textbf{Primary servers} are connected directly to a time source, like UTC. Instead \textbf{secondary servers} are synchronized, ultimately, with primary servers. The servers are connected in a logical hierarchy called a \textbf{synchronization subnet}, whose levels are called \textbf{strata}.
\image{img/NTP.png}{NTP subnet}{0.7}
The greater is the number of servers adopted the greater is the reliability provided, but this decrease the precision since the synchronization takes time and bring delays.

Server synchronization can be done:
\begin{itemize}
	\item \textbf{multicast}, common with high speed LAN with small delay.One or more servers periodically multicasts the time to the servers running in other computers connected by the LAN, which set their clocks assuming a small delay. Low precision.
	\item \textbf{procedure call}, the server is passive and waits for requests like Cristian's algorithm. More precision.
	\item \textbf{symmetrical}, servers exchange messages with timestamp, it is commonly used for low levels. More precision.
\end{itemize}


\subsection{Logical clock}
In distribute systems since we cannot synchronize clocks perfectly across a distributed system, we cannot in general use physical time to find out the order of any arbitrary pair of events occurring within it. Another interesting solution is given by \textbf{logical clock}, but first it is necessary to give some notions of \textbf{causal ordering}.

\subsubsection{Causal Ordering}
On this section we will define some formal notation that will be adopted later.
Consider $N$ processes $p_1,p_2,..., p_N$:
We write $e \rightarrow_i e^\prime$ if event $e$ occurs before $e^\prime$ in process $p_i$.
When $p_i$ sends a message $m$ to $p_j$ the event  \verb!send(m)! precedes event \verb|receive(m)|:
$$send(m) \rightarrow receive(m)$$

Causal ordering defines order between events and it has some properties:
\begin{itemize}
	\item if $\exists p_i \rightarrow e^\prime \qquad \implies \quad e \rightarrow e^\prime$ 
	\item $\forall \text{ message } m \qquad send(m) \rightarrow receive(m)$
	\item if $e,e^\prime, e^{\prime\prime}$ are events:
	 $$e \rightarrow e^{\prime}, e^\prime \rightarrow e^{\prime\prime} \qquad \implies \quad e \rightarrow e^{\prime\prime}  $$
	 \item event $a$ and $b$ can be concurrent and we denote this property as $a || b$. Meaning that they are not related.
\end{itemize}
\image{img/causalOrdering.png}{Causal ordering example}{0.8}

\subsubsection{Logical clock - Lamport timestamp}
Logical clock was introduced by Lamport in 1978, and it represents the causal ordering (\textit{happened-before}) of events. It is independent from physical clock and it is basically a software counter. Each process $p_i$ keeps its own \textbf{logical clock}, $L_i$ , which it uses to apply so-called \textbf{Lamport timestamps} to events. We denote the timestamp of event $e$ at $p_i$ by $L_i(e)$.
Processes update their logical clocks and transmit the values of their logical clocks in messages as follows:
\begin{itemize}
	\item \textbf{LC1}: $L_i$ is incremented before each event is managed at process $p_i$. In other words, $L_i$ = $L_i$ +1 $\forall$ event that occurs in $p_i$ the logical clock is \textbf{incremented}.
	\item \textbf{LC2}: if $p_i$ sends a message $m$ it sends in \textbf{piggybacking} the value $t = L_i$. if $p_j$ receives a message $(m,t)$ it sets $L_j = max(L_j, t)$ and applies \textbf{LC1} for the event \verb|receive(m)|.
\end{itemize}
\image{img/logicalClock.png}{Logical clock algorithm example}{0.7}

Logical clock has the monotonicity property, meaning that:
$$\text{If} \quad e \rightarrow e^\prime \quad \implies \quad L(e) < L(e^\prime)$$
Note that this relation is not an if-and-only-if, so if we know that $L(e) < L(e^\prime)$ we cannot infer that $e \rightarrow e^\prime$. 

\subsubsection{Logical clock - vector clock}
Some pairs of distinct events, generated by different processes, have numerically identical Lamport timestamps. However, we can create a global ordering of events by taking into account the pair (timestamp,$p_i$). If $e$ is an event occurring at $p_i$ with local timestamp $T_i$ , and $e^\prime$ is an event occurring at $p_j$ with local timestamp $T_j$ , we define the global logical timestamps for these events to be $(T_i,i)$ and $(T_j,j)$, respectively. And we define:
$$ (T_i, i) < (T_j,j) \quad \iff \quad  T_i < T_j \quad \vee \quad (T_i = T_j \wedge i < j)$$
This ordering has no general physical significance (because process identifiers are arbitrary), but it is sometimes useful.
A different ordering that overcomes the iff limitation of the Lamport definition,  $L(e) < L(e^\prime) \not\Rightarrow e < e^\prime$, is the \textbf{vector clock}.
To each process $p_i$ we associate a \textbf{vector of clocks} $V_i$ used for local timestamp.
\image{img/vectorClockAlg.png}{Vector clock algorithm }{0.8}
\begin{itemize}
	\item $V_i[i]$ represents the event number occurred in $p_i$ and marked by $p_i$.
	\item $V_i[j]$ represents the event number occurred in $p_j$ and that potentially affected $p_i$.
\end{itemize}

Then: $$V(e) < V(e^\prime) \qquad  e < e^\prime$$ 
$$V = V^\prime \quad \iff \quad V[i]=V^\prime[i] \qquad \forall i = 1,...,N$$
$$V \leq V^\prime \quad \iff \quad V[i] \leq V^\prime[i] \qquad \forall i = 1,...,N$$
$$V < V^\prime \quad \iff \quad V[i] \leq V^\prime[i] \quad \wedge \quad V \neq V^\prime \quad \qquad \forall i = 1,...,N$$

\image{img/vectorClock.png}{Vector clock algorithm example}{0.7}
The main drawback of this strategy is that it requires memory space to store the vector $V$ and message dimension increase proportional to $N$.

\subsection{Global state}
Another fundamental problem consists to verify global properties in a distributed system. We begin by giving the examples of a distribute system in which deadlock between two or more processes can happen.
\image{img/deadlockGlobalProp.png}{Global state: deadlock}{0.30}
As it is possible to see is fundamental to study properties of the system for know better what it can happen and possible issues. Knowing the \textbf{global state} of the system sometimes can solve  some problems.

The essential problem is the absence of global time. If all processes had perfectly synchronized clocks, then we could agree on a time at which each process would record its state – the result would be an actual global state of the system. From the collection of process states we could tell, for example, whether the processes were deadlocked. But we cannot achieve perfect clock synchronization, so this method is not available to us.\\

Each process $p_i$ is associated to a local state history: $h_i = <e_i^0,e_i^1,...>$. 
\begin{itemize}
	\item $e_i^k$ k-th event in the local history of $p_i$. Local state history of process $p_i$ up to $k$ is so defined: $h_i^k = <e_i^0, e_i^1,..., e_i^k>$.
	\item $s_i^k$ state of $p_i$ just after occurrence of event $e_i^k$.
	\item $s_i^0$ initial state of $p_i$.
\end{itemize}
Global state history of the set of processes $\{p_1,p_2,...,p_N\}$.
$$ H = \bigcup\limits_{i=1}^{N} h_{i}$$
$$ S = \{s_1, s_2,..., s_N\} \qquad \mathbf{global \quad state}$$\\
But now the question is spontaneous: Which are the significant states?\textbf{ Distributed snapshot} is an algorithm used to derivate a global state in which the distributed system can be. It defines a \textbf{consistent global state}.


A cut of the system’s execution is a subset of its global history that is a union of prefixes of process histories:
$$ C = \bigcup\limits_{i=1}^{N} h_{i}^{c_i} \qquad C \rightarrow \{e_1^{c_1},...,e_N^{c_N}\}$$

\subsubsection{Consistent global state}
A cut of a distributed system is said to be \textbf{consistent} if for each event included in the cut, it also includes the related events according to \textit{happened-before}:
$$\forall e \in C \quad e^{\prime} \rightarrow e \qquad \implies \qquad e^{\prime}\in C$$
\image{img/consistentState.png}{Consistent and Inconsistent cut}{0.60}
A global state is said to be consistent if it corresponds to a consistent cut. A \textbf{global execution} is a succession of global consistent states $S_0 \rightarrow S_1 \rightarrow S_2 \rightarrow ... $. A \textbf{consistent run} is an ordering of the events in a global history that is consistent with this happened-before relation o $\rightarrow$ on $H$.

\subsubsection{Distributed snapshot}
Chandy and Lamport describe a \textbf{snapshot algorithm} for determining global states of distributed systems, which we now present. The goal of the algorithm is to record a set of process and channel states (a snapshot) for a set of processes $p_i$ $(i=1,2,...,N)$ such that, even though the combination of recorded states may never have occurred at the same time, the recorded global state is consistent.
The algorithm records state locally at processes; it does not give a method for gathering the global state at one site. An obvious method for gathering the state is for all processes to send the state they recorded to a designated collector process, but we shall not address this issue further here. The algorithm assumes that:
\begin{itemize}
	\item reliable channel and communication. Neither channels nor processes fail – communication is reliable so that every message sent is eventually received intact, exactly once.
	\item Channel is unidirectional and provide FCFS-ordered message delivery.
	\item The graph of processes and channels is strongly connected (there is a path between
	any two processes).
	\item Any process may initiate a global snapshot at any time.
	\item The processes may continue their execution and send and receive normal
	messages while the snapshot takes place.
\end{itemize}
A process that starts records its own state and then sends a special message (\textbf{marker}) on all the outgoing channels to other processes to gather the global state. A process that receivers a marker message if it has not recorded its state it records it and forwards the marker on the outgoing channel, otherwise if it has already recorded its state it records the channel state (message sequence received on the channel from its last registration and before receiving the marker).

\image{img/chandyLampAlg.png}{Chandy-Lamport algorithm}{0.9}

\image{img/snapshot1.png}{Distributed snapshot 1}{1}
\image{img/snapshot2.png}{Distributed snapshot 1}{1}
\newpage


\include{CCDS11}
\include{SD10}
\include{SD11}
\include{SD12}
\include{SD13}
\include{CCDS8}
\include{CCDS12}


\include{QA}
\end{document}
